{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session-by-session generalized modeling for participant 0 - Arousal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "import json\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import neighbors\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "pd.options.mode.chained_assignment = None\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from imblearn.over_sampling import SVMSMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from crosstrainer import CrossTrainer\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = pd.read_csv(\"p0_THRI.csv\")\n",
    "data1 = pd.read_csv(\"p1_THRI.csv\")\n",
    "data2 = pd.read_csv(\"p2_THRI.csv\")\n",
    "data3 = pd.read_csv(\"p3_THRI.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of all participants' data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [data0, data1, data2, data3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the main columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cols = []\n",
    "for i in data[0].columns:\n",
    "    if 'of_' not in i and 'op_' not in i and 'ros_' not in i and 'a_' not in i:\n",
    "        basic_cols.append(i)\n",
    "        \n",
    "basic_cols = sorted(basic_cols)\n",
    "print(len(basic_cols))\n",
    "\n",
    "for i in basic_cols:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the OpenFace and OpenPose features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Face Columns\n",
    "\n",
    "of_cols = []\n",
    "for i in data[0].columns:\n",
    "    if ('of_' in i or 'op_' in i) and '_change' not in i and '_var' not in i:\n",
    "        of_cols.append(i)\n",
    "        \n",
    "of_cols = sorted(of_cols)\n",
    "print(len(of_cols))\n",
    "for i in of_cols:\n",
    "    print(\"'\"+i+\"',\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the Audio features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio Columns\n",
    "\n",
    "a_cols = []\n",
    "for i in data[0].columns:\n",
    "    if 'a_' in i and '_change' not in i and '_var' not in i:\n",
    "        a_cols.append(i)\n",
    "        \n",
    "a_cols = sorted(a_cols)\n",
    "print(len(a_cols))\n",
    "for i in a_cols:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the used performance ROS features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROS Columns\n",
    "\n",
    "ros_cols = []\n",
    "for i in data[0].columns:\n",
    "    if 'ros_' in i and '_change' not in i and '_var' not in i:\n",
    "        ros_cols.append(i)\n",
    "        \n",
    "ros_cols = sorted(ros_cols)\n",
    "print(len(ros_cols))\n",
    "\n",
    "for i in ros_cols:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the generated features from the windowing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Continuous features will have generated features named as \"feature_var\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Discrete features will have generated features named as \"feature_change\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Window Only:\n",
    "non_window_features = []\n",
    "window_features = []\n",
    "for i in data[0].columns:\n",
    "    if i not in basic_cols:\n",
    "        if 'change' in i or 'var' in i:\n",
    "            window_features.append(i)\n",
    "        else:\n",
    "            non_window_features.append(i)\n",
    "        \n",
    "window_features = sorted(window_features)\n",
    "print(len(window_features))\n",
    "for i in window_features:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the features where NaNs filled with max value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If openFace's or openPose's features are shown as NaN, there is no certain facial or body features are shown in the video frame. In this case, the value could be approximated by using the maximum value of the feature after standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns where NaNs filled with max value\n",
    "nan_max_cols = ['of_gaze_0_x',\n",
    "'of_gaze_0_y',\n",
    "'of_gaze_0_z',\n",
    "'of_gaze_1_x',\n",
    "'of_gaze_1_y',\n",
    "'of_gaze_1_z',\n",
    "'of_gaze_angle_x',\n",
    "'of_gaze_angle_y',\n",
    "'of_gaze_distance',\n",
    "'of_gaze_distance_x',\n",
    "'of_gaze_distance_y',\n",
    "'of_pose_Rxv',\n",
    "'of_pose_Ry',\n",
    "'of_pose_Rz',\n",
    "'of_pose_Tx',\n",
    "'of_pose_Ty',\n",
    "'of_pose_Tz',\n",
    "'of_pose_distance',\n",
    "'op_pose_c0',\n",
    "'op_pose_c1',\n",
    "'op_pose_c10',\n",
    "'op_pose_c11',\n",
    "'op_pose_c12',\n",
    "'op_pose_c13',\n",
    "'op_pose_c14',\n",
    "'op_pose_c15',\n",
    "'op_pose_c16',\n",
    "'op_pose_c17',\n",
    "'op_pose_c18',\n",
    "'op_pose_c19',\n",
    "'op_pose_c2',\n",
    "'op_pose_c20',\n",
    "'op_pose_c21',\n",
    "'op_pose_c22',\n",
    "'op_pose_c23',\n",
    "'op_pose_c24',\n",
    "'op_pose_c3',\n",
    "'op_pose_c4',\n",
    "'op_pose_c5',\n",
    "'op_pose_c6',\n",
    "'op_pose_c7',\n",
    "'op_pose_c8',\n",
    "'op_pose_c9',\n",
    "'op_pose_x0',\n",
    "'op_pose_x1',\n",
    "'op_pose_x10',\n",
    "'op_pose_x11',\n",
    "'op_pose_x12',\n",
    "'op_pose_x13',\n",
    "'op_pose_x14',\n",
    "'op_pose_x15',\n",
    "'op_pose_x16',\n",
    "'op_pose_x17',\n",
    "'op_pose_x18',\n",
    "'op_pose_x19',\n",
    "'op_pose_x2',\n",
    "'op_pose_x20',\n",
    "'op_pose_x21',\n",
    "'op_pose_x22',\n",
    "'op_pose_x23',\n",
    "'op_pose_x24',\n",
    "'op_pose_x3',\n",
    "'op_pose_x4',\n",
    "'op_pose_x5',\n",
    "'op_pose_x6',\n",
    "'op_pose_x7',\n",
    "'op_pose_x8',\n",
    "'op_pose_x9',\n",
    "'op_pose_y0',\n",
    "'op_pose_y1',\n",
    "'op_pose_y10',\n",
    "'op_pose_y11',\n",
    "'op_pose_y12',\n",
    "'op_pose_y13',\n",
    "'op_pose_y14',\n",
    "'op_pose_y15',\n",
    "'op_pose_y16',\n",
    "'op_pose_y17',\n",
    "'op_pose_y18',\n",
    "'op_pose_y19',\n",
    "'op_pose_y2',\n",
    "'op_pose_y20',\n",
    "'op_pose_y21',\n",
    "'op_pose_y22',\n",
    "'op_pose_y23',\n",
    "'op_pose_y24',\n",
    "'op_pose_y3',\n",
    "'op_pose_y4',\n",
    "'op_pose_y5',\n",
    "'op_pose_y6',\n",
    "'op_pose_y7',\n",
    "'op_pose_y8',\n",
    "'op_pose_y9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The main loop for the session-by-session generalized modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index of the testing participant\n",
    "test_participant_index = 0\n",
    "\n",
    "# Initialize the testing participant's data\n",
    "test_participant_data = data[test_participant_index]\n",
    "\n",
    "# Initialize a index list for training participants\n",
    "train_index_list = [0,1,2,3]\n",
    "train_index_list.remove(test_participant_index)\n",
    "\n",
    "# Initialize the testing participant's list of session numbers\n",
    "test_session_list = [1.0,2.0,3.0,4.0,5.0]\n",
    "\n",
    "# Initialize a counter for the current testing session\n",
    "current_session_counter = 1\n",
    "\n",
    "# Initialize the size of the testing participant's sessions\n",
    "size = len(test_session_list)\n",
    "\n",
    "all_scores = []\n",
    "all_y_test = []\n",
    "all_preds = []\n",
    "\n",
    "# Session-by-session generalized modeling\n",
    "while(current_session_counter < size):\n",
    "    \n",
    "    # Initialize a list for each kind of training data\n",
    "    # - train_data_list for all combinded data including both the early personal data from the test participant and data from other participants\n",
    "    # - source_list for the data from other participants\n",
    "    # - target_list for the early personal data from the test participant\n",
    "    train_data_list = []\n",
    "    source_list = []\n",
    "    target_list = []\n",
    "    \n",
    "    # Append all the training participant's data into the lists\n",
    "    for num in train_index_list:\n",
    "        train_data_list.append(data[num].copy())\n",
    "        source_list.append(data[num].copy())\n",
    "\n",
    "\n",
    "    # Initialize the test_data dataframe to hold the testing datset\n",
    "    test_data = pd.DataFrame()\n",
    "    \n",
    "    # A seperator for visual purpose of printed output\n",
    "    print('-')\n",
    "    \n",
    "    # Append the adapted session's data into the train_data_list\n",
    "    for j in range(current_session_counter):\n",
    "        print(\"train: \", test_session_list[j])\n",
    "        train_data_list.append(pd.DataFrame(test_participant_data.loc[test_participant_data['session_num'] == test_session_list[j]].copy()))\n",
    "        target_list.append(pd.DataFrame(test_participant_data.loc[test_participant_data['session_num'] == test_session_list[j]].copy()))\n",
    "        \n",
    "    print('test:', test_session_list[current_session_counter])\n",
    "    # Assign the testing session of the testing participant to the test_data\n",
    "    test_data = test_participant_data.loc[test_participant_data['session_num'] == test_session_list[current_session_counter]].copy()\n",
    "    \n",
    "    # Concat all the training dataset into one dataframe\n",
    "    train_data = pd.concat(train_data_list, ignore_index=True, sort=True)\n",
    "    source_data = pd.concat(source_list, ignore_index=True, sort=True)\n",
    "    target_data = pd.concat(target_list, ignore_index=True, sort=True)\n",
    "\n",
    "    # Seperate out the features and the labels for training and testing set \n",
    "    y_train = train_data['C_Arousal']\n",
    "    X_train = train_data.drop(columns=['C_Arousal', 'session_num', 'participant'])\n",
    "    y_test = test_data['C_Arousal']\n",
    "    X_test = test_data.drop(columns=['C_Arousal', 'session_num', 'participant']) \n",
    "    \n",
    "    y_source = source_data['C_Arousal']\n",
    "    X_source = source_data.drop(columns=['C_Arousal', 'session_num', 'participant'])\n",
    "    y_target = target_data['C_Arousal']\n",
    "    X_target = target_data.drop(columns=['C_Arousal', 'session_num', 'participant'])\n",
    "    \n",
    "     # Perform NaN standarlization and fill the NaN with corresponding values\n",
    "    for c in X_train.columns:\n",
    "\n",
    "        # Calculate the mean and std only using the data from other participants\n",
    "        mean = np.nanmean(X_source[c])\n",
    "        std = np.nanstd(X_source[c])\n",
    "        \n",
    "        if std == 0:\n",
    "            X_train[c] = (X_train[c]-mean)\n",
    "            X_test[c] = (X_test[c]-mean)\n",
    "            X_source[c] = (X_source[c]-mean)\n",
    "            X_target[c] = (X_target[c]-mean)\n",
    "        else:\n",
    "            X_train[c] = (X_train[c]-mean)/(std)\n",
    "            X_test[c] = (X_test[c]-mean)/(std)\n",
    "            X_source[c] = (X_source[c]-mean)/std\n",
    "            X_target[c] = (X_target[c]-mean)/std\n",
    "\n",
    "        # Fill in min_val for the generated values if NaN\n",
    "        if c not in nan_max_cols:\n",
    "            min_val = np.nanmin(X_source[c])\n",
    "            X_train[c] = X_train[c].fillna(min_val)\n",
    "            X_test[c] = X_test[c].fillna(min_val)\n",
    "            X_source[c] = X_source[c].fillna(min_val)\n",
    "            X_target[c] = X_target[c].fillna(min_val)\n",
    "        # Fill in max_val for the openFace or OpenPose features if NaN\n",
    "        else:\n",
    "            max_val = np.nanmax(X_source[c])\n",
    "\n",
    "            X_train[c] = X_train[c].fillna(max_val)\n",
    "            X_test[c] = X_test[c].fillna(max_val) \n",
    "            X_source[c] = X_source[c].fillna(max_val)\n",
    "            X_target[c] = X_target[c].fillna(max_val)\n",
    "\n",
    "# ---------------------Model goes here-----------------------------------------\n",
    "\n",
    "    model = XGBClassifier(n_estimators=100, max_depth = 6, booster = 'gbtree')\n",
    "                    \n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "    # Display the shape of the training and testing dataframe for each adaptation\n",
    "    print(X_train.shape)\n",
    "    print(X_source.shape)\n",
    "    print(X_target.shape)\n",
    "    print(X_test.shape)\n",
    "    \n",
    "\n",
    "    # Train the model with only the data from other participants\n",
    "    model.fit(X_source,y_source)\n",
    "\n",
    "    # Obtain the testing results\n",
    "    scores = model.predict(X_test)\n",
    "    probs = model.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    preds = pd.DataFrame(preds)\n",
    "    scores = pd.DataFrame(scores)\n",
    "    \n",
    "    all_preds.append(preds)\n",
    "    all_scores.append(scores)\n",
    "    all_y_test.append(y_test)\n",
    "    \n",
    "    # Move the counter one index forward\n",
    "    current_session_counter += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_scores = pd.concat(all_scores, ignore_index=True)\n",
    "df_all_y_test = pd.concat(all_y_test, ignore_index=True)\n",
    "df_all_preds = pd.concat(all_preds,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_accuracy = accuracy_score(df_all_y_test, df_all_scores)\n",
    "avg_auc = roc_auc_score(df_all_y_test, df_all_preds)\n",
    "avg_precision = metrics.precision_score(df_all_y_test, df_all_scores, average=None)\n",
    "avg_recall = metrics.recall_score(df_all_y_test, df_all_scores, average=None)\n",
    "avg_f1 = metrics.f1_score(df_all_y_test, df_all_scores, average=None)\n",
    "print(avg_auc)\n",
    "print(avg_accuracy)\n",
    "print(avg_f1)\n",
    "print(avg_precision)\n",
    "print(avg_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df_all_scores).to_csv(\"p0_gen_xgb_arousal_all_scores.csv\",index = False)\n",
    "pd.DataFrame(df_all_y_test).to_csv(\"p0_gen_xgb_arousal_y_test.csv\",index = False)\n",
    "pd.DataFrame(df_all_preds).to_csv(\"p0_gen_xgb_arousal_all_preds.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
